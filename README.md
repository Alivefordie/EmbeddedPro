# EmbeddedPro

EmbeddedPro เป็นชุดสคริปต์ Python, โค้ดสำหรับ ESP32 (Arduino) และไฟล์โมเดลสำหรับงานวิสัยทัศน์ฝังตัวและงานเสียง โดยเน้นโปรเจกต์ตรวจจับวัตถุด้วย YOLO (เช่นการตรวจจับ "rubber duck") พร้อมเครื่องมือช่วยสำหรับการตรวจจับสี, การสื่อสารกับ ESP32 ผ่านพอร์ตอนุกรม และการสังเคราะห์เสียง

## โครงสร้างโปรเจกต์

- `*.py` - สคริปต์ Python สำหรับการตรวจจับ, งานเสียง, TTS และการสื่อสารกับอุปกรณ์
  - `yolo_duck.py` - ใช้โมเดล YOLO (`best.pt`) เพื่อรันการตรวจจับบนรูปภาพหรือวิดีโอ
  - `color_detect.py` - เครื่องมือสำหรับตรวจจับสีในภาพ
  - `esp32_serial.py` - สื่อสารกับ ESP32 ผ่านพอร์ตอนุกรม (serial)
  - `tts.py` - ตัวอย่างการใช้ Text-to-Speech (gTTS)
  - `clean_code.py` / `dirty_code.py` - เวอร์ชันที่ปรับแต่งแล้วและเวอร์ชันดั้งเดิมของสคริปต์บางตัว
  - ไฟล์อื่น ๆ เช่น `fifty.py`, `no_control.py`, โฟลเดอร์ `32-cam_not_use/`, `ESP32_BT_PWM_SERVO/` เป็นยูทิลิตี้และสเก็ตช์ Arduino
- `best.pt` - ค่าน้ำหนักของโมเดล YOLO ที่ฝึกแล้ว
- `runs/` - ผลการฝึกและภาพแสดงผล (plots, weights, results)
- `img_test/` - รูปภาพและวิดีโอสำหรับทดสอบ
- `data/` - ไฟล์เสียง (เช่น `help.wav`)

## เริ่มต้นอย่างรวดเร็ว (Quick start)

ข้อกำหนดเบื้องต้น:

- แนะนำ Python 3.8 ขึ้นไป
- ติดตั้ง dependency (ตัวอย่างที่พบบ่อย):

```bash
pip install -r requirements.txt
```

## ข้อควรระวัง

- ตรวจสอบโค้ด Python และ Arduino ก่อนรัน โดยเฉพาะส่วนที่ติดต่อฮาร์ดแวร์หรือพอร์ตอนุกรม การรันโค้ดที่ไม่รู้จักอาจส่งคำสั่งไปยังอุปกรณ์จริง
- ไฟล์น้ำหนักโมเดล (`best.pt`) อาจมีขนาดใหญ่ โปรดตรวจสอบพื้นที่ว่างของดิสก์

### yolo_duck.py

- คำอธิบาย: รันการตรวจจับแบบเรียลไทม์จากกล้องเว็บแคมโดยใช้ Ultralytics YOLO (`best.pt`) แล้วแสดงกรอบและ centroid
- พารามิเตอร์ที่พบ: ไม่มี CLI flags โดยตรง
- ตัวแปรสำคัญภายในไฟล์:
  - `model = YOLO("./best.pt")` — เปลี่ยนพาธน้ำหนักหากต้องการ
  - `TARGET_CLASS_NAME` — ตั้งเป็นชื่อคลาสที่จะจับหรือ `None` เพื่อยอมรับทุกคลาส
  - `device` ถูกเลือกอัตโนมัติ (CUDA ถ้ามี)
- วิธีรัน:

```
python yolo_duck.py
```

- หมายเหตุ: หากต้องการใช้วิดีโอแทนเว็บแคม ให้แก้โค้ดที่สร้าง `cv2.VideoCapture(0)` เป็น `cv2.VideoCapture("img_test/footage.mp4")` หรือสร้าง wrapper ที่รับพาธเป็น arg

### color_detect.py

- คำอธิบาย: ตัวช่วยตรวจจับสี — เปิดกล้อง, คลิกเลือกพิกเซลเพื่อตั้งเป้าสี, ปรับ tolerance ด้วยปุ่ม +/-
- พารามิเตอร์ที่พบ: ไม่มี CLI flags
- คีย์ที่ใช้งานภายในโปรแกรม:
  - คลิกซ้าย: เลือกสีจากพิกเซล
  - ปุ่ม + / - : เพิ่ม/ลด tolerance (ΔH, ΔS, ΔV)
  - q : ออกจากโปรแกรม
- วิธีรัน:

```
python color_detect.py
```

### esp32_serial.py

- คำอธิบาย: โปรแกรมคอนโซลสำหรับเชื่อมต่อกับ ESP32 ผ่านพอร์ตอนุกรม (read loop + ส่งข้อความจาก stdin)
- ตัวแปรสำคัญ:
  - `PORT = "COM11"` — เปลี่ยนเป็นพอร์ตของคุณ (Windows) หรือ `"/dev/tty..."` บน Linux/Mac
  - `BAUD = 115200`
- พารามิเตอร์ที่พบ: ไม่มี CLI flags — ให้แก้ตัวแปรในไฟล์หรือทำ wrapper
- วิธีรัน:

```
python esp32_serial.py
```

เมื่อเชื่อมต่อแล้ว พิมพ์คำสั่งแล้วกด Enter เพื่อส่ง (สคริปต์จะต่อท้าย newline ให้)

### tts.py

- คำอธิบาย: ตัวอย่างสั้นๆ ที่ใช้ gTTS สร้างไฟล์ MP3
- พารามิเตอร์ที่พบ: ไม่มี CLI flags — ข้อความและพาธไฟล์ถูก hard-coded
- วิธีแก้เพื่อใช้งานจริง: แก้สตริงข้อความหรือเพิ่ม argparse เพื่อรับ `--text` และ `--out`
- วิธีรัน (ปัจจุบัน):

```
python tts.py
```

จะสร้างไฟล์ `help.mp3` ตามสคริปต์

### clean_code.py / dirty_code.py / no_control.py

- คำอธิบายย่อ: สคริปต์กลุ่มนี้เป็น pipeline สำหรับ
  - ตรวจจับวัตถุด้วย YOLO (ใช้ `ultralytics.YOLO` กับ `best.pt`)
  - แปลงพิกัดจากมุมกล้องเป็น BEV (bird's-eye view) ด้วยเมตริกซ์ `H` ที่ได้จากการคลิก 4 จุด
  - คำนวณพิกัดเป้าหมายและสั่งการหุ่นยนต์/เรือผ่านพอร์ตอนุกรม (serial)

รายละเอียดเชิงลึก

1. ความสามารถหลัก

- การตรวจจับ: ใช้ `model.predict(...)` เพื่อรับกล่อง (boxes), confidence และคลาส
- BEV mapping: ใช้ `cv2.perspectiveTransform` ร่วมกับ `H` เพื่อแปลง centroid เป็นพิกัด BEV
- Autopilot / control logic: ฟังก์ชัน `autopilot_step(...)` จะคำนวณระยะและมุม (bearing, yaw) แล้วสั่ง `send_forward`, `send_left`, `send_right`, `send_stop` ผ่าน serial

2. ตัวแปรสำคัญที่ควรตรวจสอบก่อนรัน

- Serial / comms:
  - `PORT` (ตัวอย่าง: `COM11` บน Windows หรือ `/dev/ttyUSB0` บน Linux)
  - `BAUD` (ตัวอย่าง: `115200`)
  - `TIMEOUT_S`
- โมเดลและ device:
  - `model = YOLO("./best.pt")` — ชี้ไปที่ไฟล์น้ำหนัก
  - `device` — ค่า default ตั้งตาม `torch.cuda.is_available()` (สามารถบังคับเป็น `'cpu'` ได้)
- พารามิเตอร์การขับเคลื่อน:
  - `FWD_PWM_BASE`, `ROT_PWM_BASE`, `MAX_PWM`, `K_ROT`
  - `STOP_DIST_M` — ระยะ (เมตร) ที่ถือว่า "ถึงเป้าหมาย"

3. อินเทอร์แอคชัน (เมาส์/คีย์บอร์ด)

- เมาส์: L-click เพื่อเพิ่มจุด calibration (หรือเลือกพิกัด), R-click เพื่อ undo
- คีย์บอร์ด: `q` เพื่อออก, บางไฟล์มีปุ่ม +/- เพื่อปรับ tolerance ของการตรวจจับสี

4. ตัวอย่างการใช้งานเชิงลึก (แนะนำให้ทดสอบแบบ dry-run ก่อนต่อฮาร์ดแวร์)

- ตั้งค่าก่อนรัน (แก้ในไฟล์หรือใช้ wrapper CLI ที่ผมสามารถเพิ่มให้):

```python
PORT = 'COM11'
BAUD = 115200
model = YOLO('./best.pt')
FWD_PWM_BASE = 130
ROT_PWM_BASE = 120
STOP_DIST_M = 0.3
```

- เรียกใช้งาน (basic):

```bash
python clean_code.py
```

- พฤติกรรมตอนรัน:
  - สคริปต์จะพยายามเปิดกล้องและ (ถ้ามี) พอร์ต serial
  - ถ้าเปิดพอร์ตไม่ได้ บางไฟล์จะทำงานในโหมด DRYRUN (พิมพ์คำสั่งแทนการส่งจริง)
  - ให้คลิก 4 จุดบนภาพเพื่อสร้างเมทริกซ์ `H` สำหรับ BEV (ถ้าสคริปต์ต้องการ)

5. ความปลอดภัยและคำแนะนำเชิงปฏิบัติ

- อย่าเชื่อมต่อฮาร์ดแวร์จริงในครั้งแรก — ให้รันในโหมด DRYRUN หรือจำลอง serial ก่อน
- ลดค่า `FWD_PWM_BASE` / `ROT_PWM_BASE` เมื่อลองบนอุปกรณ์จริงครั้งแรก
- ตรวจสอบว่าโปรโตคอลข้อความ serial ตรงกับฝั่ง MCU (ตัวอย่าง: `F-128\n`)

### fifty.py

- คำอธิบาย: ตัวอย่างใช้งาน FiftyOne เพื่อดู dataset (ต้องติดตั้ง `fiftyone`)
- ตัวแปรสำคัญ: `ROOT = "./dataset"` — เปลี่ยนเป็น root ของ dataset
- วิธีรัน:

```
python fifty.py
```

จะเปิดเว็บ UI ของ FiftyOne ในเบราเซอร์
